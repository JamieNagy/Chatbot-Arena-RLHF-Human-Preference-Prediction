{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6354029c",
      "metadata": {
        "papermill": {
          "duration": 0.011156,
          "end_time": "2024-07-11T07:12:42.298620",
          "exception": false,
          "start_time": "2024-07-11T07:12:42.287464",
          "status": "completed"
        },
        "tags": [],
        "id": "6354029c"
      },
      "source": [
        "This takes around 4 hours with `max_length=2048` without TTA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f64440d",
      "metadata": {
        "_kg_hide-input": false,
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2024-07-11T07:12:42.322453Z",
          "iopub.status.busy": "2024-07-11T07:12:42.321698Z",
          "iopub.status.idle": "2024-07-11T07:13:14.573511Z",
          "shell.execute_reply": "2024-07-11T07:13:14.572564Z"
        },
        "papermill": {
          "duration": 32.266372,
          "end_time": "2024-07-11T07:13:14.575957",
          "exception": false,
          "start_time": "2024-07-11T07:12:42.309585",
          "status": "completed"
        },
        "scrolled": true,
        "tags": [],
        "id": "0f64440d"
      },
      "outputs": [],
      "source": [
        "!pip install transformers peft accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce0de612",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-11T07:13:14.602907Z",
          "iopub.status.busy": "2024-07-11T07:13:14.602575Z",
          "iopub.status.idle": "2024-07-11T07:13:36.997641Z",
          "shell.execute_reply": "2024-07-11T07:13:36.996748Z"
        },
        "papermill": {
          "duration": 22.411137,
          "end_time": "2024-07-11T07:13:37.000214",
          "exception": false,
          "start_time": "2024-07-11T07:13:14.589077",
          "status": "completed"
        },
        "tags": [],
        "id": "ce0de612",
        "outputId": "e62928f0-ac56-40ca-e75f-eeb4cd0eb349"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-07-11 07:13:24.811517: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-11 07:13:24.811656: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-11 07:13:24.981702: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from dataclasses import dataclass\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "import torch\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import Gemma2ForSequenceClassification, GemmaTokenizerFast, BitsAndBytesConfig\n",
        "from transformers.data.data_collator import pad_without_fast_tokenizer_warning\n",
        "from peft import PeftModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddd17322",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-11T07:13:37.027948Z",
          "iopub.status.busy": "2024-07-11T07:13:37.027284Z",
          "iopub.status.idle": "2024-07-11T07:13:37.059615Z",
          "shell.execute_reply": "2024-07-11T07:13:37.058768Z"
        },
        "papermill": {
          "duration": 0.048495,
          "end_time": "2024-07-11T07:13:37.061899",
          "exception": false,
          "start_time": "2024-07-11T07:13:37.013404",
          "status": "completed"
        },
        "tags": [],
        "id": "ddd17322"
      },
      "outputs": [],
      "source": [
        "assert torch.cuda.device_count() == 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b323b36",
      "metadata": {
        "papermill": {
          "duration": 0.012559,
          "end_time": "2024-07-11T07:13:37.087405",
          "exception": false,
          "start_time": "2024-07-11T07:13:37.074846",
          "status": "completed"
        },
        "tags": [],
        "id": "9b323b36"
      },
      "source": [
        "## Configurations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cfe1c35",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-11T07:13:37.114559Z",
          "iopub.status.busy": "2024-07-11T07:13:37.114246Z",
          "iopub.status.idle": "2024-07-11T07:13:37.119933Z",
          "shell.execute_reply": "2024-07-11T07:13:37.118965Z"
        },
        "papermill": {
          "duration": 0.021153,
          "end_time": "2024-07-11T07:13:37.121924",
          "exception": false,
          "start_time": "2024-07-11T07:13:37.100771",
          "status": "completed"
        },
        "tags": [],
        "id": "9cfe1c35"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Config:\n",
        "    gemma_dir = 'my_input/gemma-2/transformers/gemma-2-9b-it-4bit/1/gemma-2-9b-it-4bit'\n",
        "    lora_dir = 'my_input/73zap2gx/checkpoint-5748'\n",
        "    max_length = 2048\n",
        "    batch_size = 4\n",
        "    device = torch.device(\"cuda\")\n",
        "    tta = False\n",
        "    spread_max_length = False\n",
        "\n",
        "cfg = Config()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "907e1f26",
      "metadata": {
        "papermill": {
          "duration": 0.01269,
          "end_time": "2024-07-11T07:13:37.147413",
          "exception": false,
          "start_time": "2024-07-11T07:13:37.134723",
          "status": "completed"
        },
        "tags": [],
        "id": "907e1f26"
      },
      "source": [
        "# Load & pre-process Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1f540c5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-11T07:13:37.175264Z",
          "iopub.status.busy": "2024-07-11T07:13:37.174958Z",
          "iopub.status.idle": "2024-07-11T07:13:37.190381Z",
          "shell.execute_reply": "2024-07-11T07:13:37.189593Z"
        },
        "papermill": {
          "duration": 0.031967,
          "end_time": "2024-07-11T07:13:37.192397",
          "exception": false,
          "start_time": "2024-07-11T07:13:37.160430",
          "status": "completed"
        },
        "tags": [],
        "id": "e1f540c5"
      },
      "outputs": [],
      "source": [
        "test = pd.read_csv('my_input/lmsys-chatbot-arena/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66d9d27f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-11T07:13:37.221965Z",
          "iopub.status.busy": "2024-07-11T07:13:37.221612Z",
          "iopub.status.idle": "2024-07-11T07:13:37.246133Z",
          "shell.execute_reply": "2024-07-11T07:13:37.245248Z"
        },
        "papermill": {
          "duration": 0.041302,
          "end_time": "2024-07-11T07:13:37.248266",
          "exception": false,
          "start_time": "2024-07-11T07:13:37.206964",
          "status": "completed"
        },
        "tags": [],
        "id": "66d9d27f",
        "outputId": "318e639e-c63a-4d6e-c682-15048aca9dfa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>prompt</th>\n",
              "      <th>response_a</th>\n",
              "      <th>response_b</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>136060</td>\n",
              "      <td>I have three oranges today, I ate an orange ye...</td>\n",
              "      <td>You have two oranges today.</td>\n",
              "      <td>You still have three oranges. Eating an orange...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>211333</td>\n",
              "      <td>You are a mediator in a heated political debat...</td>\n",
              "      <td>Thank you for sharing the details of the situa...</td>\n",
              "      <td>Mr Reddy and Ms Blue both have valid points in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1233961</td>\n",
              "      <td>How to initialize the classification head when...</td>\n",
              "      <td>When you want to initialize the classification...</td>\n",
              "      <td>To initialize the classification head when per...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                             prompt  \\\n",
              "0   136060  I have three oranges today, I ate an orange ye...   \n",
              "1   211333  You are a mediator in a heated political debat...   \n",
              "2  1233961  How to initialize the classification head when...   \n",
              "\n",
              "                                          response_a  \\\n",
              "0                        You have two oranges today.   \n",
              "1  Thank you for sharing the details of the situa...   \n",
              "2  When you want to initialize the classification...   \n",
              "\n",
              "                                          response_b  \n",
              "0  You still have three oranges. Eating an orange...  \n",
              "1  Mr Reddy and Ms Blue both have valid points in...  \n",
              "2  To initialize the classification head when per...  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def process_text(text: str) -> str:\n",
        "    return \" \".join(eval(text, {\"null\": \"\"}))\n",
        "\n",
        "test.loc[:, 'prompt'] = test['prompt'].apply(process_text)\n",
        "test.loc[:, 'response_a'] = test['response_a'].apply(process_text)\n",
        "test.loc[:, 'response_b'] = test['response_b'].apply(process_text)\n",
        "\n",
        "display(test.head(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cb30182",
      "metadata": {
        "papermill": {
          "duration": 0.01264,
          "end_time": "2024-07-11T07:13:37.274083",
          "exception": false,
          "start_time": "2024-07-11T07:13:37.261443",
          "status": "completed"
        },
        "tags": [],
        "id": "2cb30182"
      },
      "source": [
        "# Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f513d7e5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-11T07:13:37.300496Z",
          "iopub.status.busy": "2024-07-11T07:13:37.300137Z",
          "iopub.status.idle": "2024-07-11T07:13:37.308827Z",
          "shell.execute_reply": "2024-07-11T07:13:37.307928Z"
        },
        "papermill": {
          "duration": 0.02445,
          "end_time": "2024-07-11T07:13:37.310934",
          "exception": false,
          "start_time": "2024-07-11T07:13:37.286484",
          "status": "completed"
        },
        "tags": [],
        "id": "f513d7e5"
      },
      "outputs": [],
      "source": [
        "def tokenize(\n",
        "    tokenizer, prompt, response_a, response_b, max_length=cfg.max_length, spread_max_length=cfg.spread_max_length\n",
        "):\n",
        "    prompt = [\"<prompt>: \" + p for p in prompt]\n",
        "    response_a = [\"\\n\\n<response_a>: \" + r_a for r_a in response_a]\n",
        "    response_b = [\"\\n\\n<response_b>: \" + r_b for r_b in response_b]\n",
        "    if spread_max_length:\n",
        "        prompt = tokenizer(prompt, max_length=max_length//3, truncation=True, padding=False).input_ids\n",
        "        response_a = tokenizer(response_a, max_length=max_length//3, truncation=True, padding=False).input_ids\n",
        "        response_b = tokenizer(response_b, max_length=max_length//3, truncation=True, padding=False).input_ids\n",
        "        input_ids = [p + r_a + r_b for p, r_a, r_b in zip(prompt, response_a, response_b)]\n",
        "        attention_mask = [[1]* len(i) for i in input_ids]\n",
        "    else:\n",
        "        text = [p + r_a + r_b for p, r_a, r_b in zip(prompt, response_a, response_b)]\n",
        "        tokenized = tokenizer(text, max_length=max_length, truncation=True, padding=False)\n",
        "        input_ids = tokenized.input_ids\n",
        "        attention_mask = tokenized.attention_mask\n",
        "    return input_ids, attention_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe580aba",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-11T07:13:37.337858Z",
          "iopub.status.busy": "2024-07-11T07:13:37.337559Z",
          "iopub.status.idle": "2024-07-11T07:13:38.533078Z",
          "shell.execute_reply": "2024-07-11T07:13:38.531909Z"
        },
        "papermill": {
          "duration": 1.212376,
          "end_time": "2024-07-11T07:13:38.535822",
          "exception": false,
          "start_time": "2024-07-11T07:13:37.323446",
          "status": "completed"
        },
        "tags": [],
        "id": "fe580aba",
        "outputId": "fc36df9d-97fe-4bba-d13f-d83d4c21281c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 874 ms, sys: 151 ms, total: 1.02 s\n",
            "Wall time: 1.19 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "tokenizer = GemmaTokenizerFast.from_pretrained(cfg.gemma_dir)\n",
        "tokenizer.add_eos_token = True\n",
        "tokenizer.padding_side = \"right\"\n",
        "\n",
        "data = pd.DataFrame()\n",
        "data[\"id\"] = test[\"id\"]\n",
        "data[\"input_ids\"], data[\"attention_mask\"] = tokenize(tokenizer, test[\"prompt\"], test[\"response_a\"], test[\"response_b\"])\n",
        "data[\"length\"] = data[\"input_ids\"].apply(len)\n",
        "\n",
        "aug_data = pd.DataFrame()\n",
        "aug_data[\"id\"] = test[\"id\"]\n",
        "# swap response_a & response_b\n",
        "aug_data['input_ids'], aug_data['attention_mask'] = tokenize(tokenizer, test[\"prompt\"], test[\"response_b\"], test[\"response_a\"])\n",
        "aug_data[\"length\"] = aug_data[\"input_ids\"].apply(len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56f0c0f1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-11T07:13:38.572484Z",
          "iopub.status.busy": "2024-07-11T07:13:38.572078Z",
          "iopub.status.idle": "2024-07-11T07:13:38.580159Z",
          "shell.execute_reply": "2024-07-11T07:13:38.578648Z"
        },
        "papermill": {
          "duration": 0.026394,
          "end_time": "2024-07-11T07:13:38.582296",
          "exception": false,
          "start_time": "2024-07-11T07:13:38.555902",
          "status": "completed"
        },
        "tags": [],
        "id": "56f0c0f1",
        "outputId": "42e7da27-db67-43e8-833b-259b8d5c0182"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<bos><prompt>: I have three oranges today, I ate an orange yesterday. How many oranges do I have?\n",
            "\n",
            "<response_a>: You have two oranges today.\n",
            "\n",
            "<response_b>: You still have three oranges. Eating an orange yesterday does not affect the number of oranges you have today.<eos>\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.decode(data[\"input_ids\"][0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b901543",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-11T07:13:38.611144Z",
          "iopub.status.busy": "2024-07-11T07:13:38.610765Z",
          "iopub.status.idle": "2024-07-11T07:13:38.617778Z",
          "shell.execute_reply": "2024-07-11T07:13:38.616760Z"
        },
        "papermill": {
          "duration": 0.024783,
          "end_time": "2024-07-11T07:13:38.620520",
          "exception": false,
          "start_time": "2024-07-11T07:13:38.595737",
          "status": "completed"
        },
        "tags": [],
        "id": "9b901543",
        "outputId": "075642a8-6d3a-4c5e-8cbb-f2b8d2428247"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<bos><prompt>: I have three oranges today, I ate an orange yesterday. How many oranges do I have?\n",
            "\n",
            "<response_a>: You still have three oranges. Eating an orange yesterday does not affect the number of oranges you have today.\n",
            "\n",
            "<response_b>: You have two oranges today.<eos>\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.decode(aug_data[\"input_ids\"][0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5880f656",
      "metadata": {
        "papermill": {
          "duration": 0.013611,
          "end_time": "2024-07-11T07:13:38.647492",
          "exception": false,
          "start_time": "2024-07-11T07:13:38.633881",
          "status": "completed"
        },
        "tags": [],
        "id": "5880f656"
      },
      "source": [
        "# Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "054f1949",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-11T07:13:38.677223Z",
          "iopub.status.busy": "2024-07-11T07:13:38.676938Z",
          "iopub.status.idle": "2024-07-11T07:14:53.267474Z",
          "shell.execute_reply": "2024-07-11T07:14:53.266301Z"
        },
        "papermill": {
          "duration": 74.609302,
          "end_time": "2024-07-11T07:14:53.270169",
          "exception": false,
          "start_time": "2024-07-11T07:13:38.660867",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "26611c111dad4ff9b87bf5efea4ffd44",
            "c48821c725e14616bc3936f7e3a97b60"
          ]
        },
        "id": "054f1949",
        "outputId": "b81fb48e-ae67-4704-9d7b-4c36723af380"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "26611c111dad4ff9b87bf5efea4ffd44",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c48821c725e14616bc3936f7e3a97b60",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load base model on GPU 0\n",
        "device_0 = torch.device('cuda:0')\n",
        "model_0 = Gemma2ForSequenceClassification.from_pretrained(\n",
        "    cfg.gemma_dir,\n",
        "    device_map=device_0,\n",
        "    use_cache=False,\n",
        ")\n",
        "\n",
        "# Load base model on GPU 1\n",
        "device_1 = torch.device('cuda:1')\n",
        "model_1 = Gemma2ForSequenceClassification.from_pretrained(\n",
        "    cfg.gemma_dir,\n",
        "    device_map=device_1,\n",
        "    use_cache=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8bdcc15",
      "metadata": {
        "papermill": {
          "duration": 0.015108,
          "end_time": "2024-07-11T07:14:53.300600",
          "exception": false,
          "start_time": "2024-07-11T07:14:53.285492",
          "status": "completed"
        },
        "tags": [],
        "id": "a8bdcc15"
      },
      "source": [
        "#### Load LoRA adapter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5ba96a9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-11T07:14:53.331178Z",
          "iopub.status.busy": "2024-07-11T07:14:53.330801Z",
          "iopub.status.idle": "2024-07-11T07:14:54.399607Z",
          "shell.execute_reply": "2024-07-11T07:14:54.398768Z"
        },
        "papermill": {
          "duration": 1.086772,
          "end_time": "2024-07-11T07:14:54.402044",
          "exception": false,
          "start_time": "2024-07-11T07:14:53.315272",
          "status": "completed"
        },
        "tags": [],
        "id": "a5ba96a9"
      },
      "outputs": [],
      "source": [
        "model_0 = PeftModel.from_pretrained(model_0, cfg.lora_dir)\n",
        "model_1 = PeftModel.from_pretrained(model_1, cfg.lora_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d640efa",
      "metadata": {
        "papermill": {
          "duration": 0.01366,
          "end_time": "2024-07-11T07:14:54.430724",
          "exception": false,
          "start_time": "2024-07-11T07:14:54.417064",
          "status": "completed"
        },
        "tags": [],
        "id": "3d640efa"
      },
      "source": [
        "# Inference\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cfca971",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-11T07:14:54.459943Z",
          "iopub.status.busy": "2024-07-11T07:14:54.459637Z",
          "iopub.status.idle": "2024-07-11T07:14:54.469828Z",
          "shell.execute_reply": "2024-07-11T07:14:54.468832Z"
        },
        "papermill": {
          "duration": 0.027235,
          "end_time": "2024-07-11T07:14:54.471942",
          "exception": false,
          "start_time": "2024-07-11T07:14:54.444707",
          "status": "completed"
        },
        "tags": [],
        "id": "4cfca971"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "@torch.cuda.amp.autocast()\n",
        "def inference(df, model, device, batch_size=cfg.batch_size, max_length=cfg.max_length):\n",
        "    a_win, b_win, tie = [], [], []\n",
        "\n",
        "    for start_idx in range(0, len(df), batch_size):\n",
        "        end_idx = min(start_idx + batch_size, len(df))\n",
        "        tmp = df.iloc[start_idx:end_idx]\n",
        "        input_ids = tmp[\"input_ids\"].to_list()\n",
        "        attention_mask = tmp[\"attention_mask\"].to_list()\n",
        "        inputs = pad_without_fast_tokenizer_warning(\n",
        "            tokenizer,\n",
        "            {\"input_ids\": input_ids, \"attention_mask\": attention_mask},\n",
        "            padding=\"longest\",\n",
        "            pad_to_multiple_of=None,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        outputs = model(**inputs.to(device))\n",
        "        proba = outputs.logits.softmax(-1).cpu()\n",
        "\n",
        "        a_win.extend(proba[:, 0].tolist())\n",
        "        b_win.extend(proba[:, 1].tolist())\n",
        "        tie.extend(proba[:, 2].tolist())\n",
        "\n",
        "    df[\"winner_model_a\"] = a_win\n",
        "    df[\"winner_model_b\"] = b_win\n",
        "    df[\"winner_tie\"] = tie\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac49e0c2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-11T07:14:54.502181Z",
          "iopub.status.busy": "2024-07-11T07:14:54.501892Z",
          "iopub.status.idle": "2024-07-11T07:14:59.267609Z",
          "shell.execute_reply": "2024-07-11T07:14:59.266492Z"
        },
        "papermill": {
          "duration": 4.782939,
          "end_time": "2024-07-11T07:14:59.269852",
          "exception": false,
          "start_time": "2024-07-11T07:14:54.486913",
          "status": "completed"
        },
        "tags": [],
        "id": "ac49e0c2",
        "outputId": "eb3ed28b-2933-4c8d-c952-eef9fd29ed59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "elapsed time: 4.758451461791992\n"
          ]
        }
      ],
      "source": [
        "st = time.time()\n",
        "\n",
        "# sort by input length to fully leverage dynaminc padding\n",
        "data = data.sort_values(\"length\", ascending=False)\n",
        "# the total #tokens in sub_1 and sub_2 should be more or less the same\n",
        "sub_1 = data.iloc[0::2].copy()\n",
        "sub_2 = data.iloc[1::2].copy()\n",
        "\n",
        "with ThreadPoolExecutor(max_workers=2) as executor:\n",
        "    results = executor.map(inference, (sub_1, sub_2), (model_0, model_1), (device_0, device_1))\n",
        "\n",
        "result_df = pd.concat(list(results), axis=0)\n",
        "proba = result_df[[\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]].values\n",
        "\n",
        "print(f\"elapsed time: {time.time() - st}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c98ff1f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-11T07:14:59.300419Z",
          "iopub.status.busy": "2024-07-11T07:14:59.300070Z",
          "iopub.status.idle": "2024-07-11T07:14:59.308422Z",
          "shell.execute_reply": "2024-07-11T07:14:59.307286Z"
        },
        "papermill": {
          "duration": 0.0259,
          "end_time": "2024-07-11T07:14:59.310630",
          "exception": false,
          "start_time": "2024-07-11T07:14:59.284730",
          "status": "completed"
        },
        "tags": [],
        "id": "5c98ff1f",
        "outputId": "846a4d24-1fc8-4da6-b794-b8e7aa090239"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "elapsed time: 0.0001938343048095703\n"
          ]
        }
      ],
      "source": [
        "st = time.time()\n",
        "\n",
        "if cfg.tta:\n",
        "    data = aug_data.sort_values(\"length\", ascending=False)  # sort by input length to boost speed\n",
        "    sub_1 = data.iloc[0::2].copy()\n",
        "    sub_2 = data.iloc[1::2].copy()\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=2) as executor:\n",
        "        results = executor.map(inference, (sub_1, sub_2), (model_0, model_1), (device_0, device_1))\n",
        "\n",
        "    tta_result_df = pd.concat(list(results), axis=0)\n",
        "    # recall TTA's order is flipped\n",
        "    tta_proba = tta_result_df[[\"winner_model_b\", \"winner_model_a\", \"winner_tie\"]].values\n",
        "    # average original result and TTA result.\n",
        "    proba = (proba + tta_proba) / 2\n",
        "\n",
        "print(f\"elapsed time: {time.time() - st}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c17adaf2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-11T07:14:59.340182Z",
          "iopub.status.busy": "2024-07-11T07:14:59.339917Z",
          "iopub.status.idle": "2024-07-11T07:14:59.357113Z",
          "shell.execute_reply": "2024-07-11T07:14:59.356114Z"
        },
        "papermill": {
          "duration": 0.034496,
          "end_time": "2024-07-11T07:14:59.359344",
          "exception": false,
          "start_time": "2024-07-11T07:14:59.324848",
          "status": "completed"
        },
        "tags": [],
        "id": "c17adaf2",
        "outputId": "d077872c-b566-4428-b69f-58204ae4c769"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>winner_model_a</th>\n",
              "      <th>winner_model_b</th>\n",
              "      <th>winner_tie</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1233961</td>\n",
              "      <td>0.146055</td>\n",
              "      <td>0.644424</td>\n",
              "      <td>0.209521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>136060</td>\n",
              "      <td>0.006395</td>\n",
              "      <td>0.962159</td>\n",
              "      <td>0.031446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>211333</td>\n",
              "      <td>0.340726</td>\n",
              "      <td>0.243892</td>\n",
              "      <td>0.415382</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  winner_model_a  winner_model_b  winner_tie\n",
              "2  1233961        0.146055        0.644424    0.209521\n",
              "0   136060        0.006395        0.962159    0.031446\n",
              "1   211333        0.340726        0.243892    0.415382"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "result_df.loc[:, \"winner_model_a\"] = proba[:, 0]\n",
        "result_df.loc[:, \"winner_model_b\"] = proba[:, 1]\n",
        "result_df.loc[:, \"winner_tie\"] = proba[:, 2]\n",
        "deploy_df = result_df[[\"id\", 'winner_model_a', 'winner_model_b', 'winner_tie']]\n",
        "deploy_df.to_csv('deploy_sheet.csv', index=False)\n",
        "display(deploy_df)"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "databundleVersionId": 8346466,
          "sourceId": 66631,
          "sourceType": "competition"
        },
        {
          "datasetId": 5297895,
          "sourceId": 8897601,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 5369301,
          "sourceId": 8926343,
          "sourceType": "datasetVersion"
        },
        {
          "modelInstanceId": 63082,
          "sourceId": 75103,
          "sourceType": "modelInstanceVersion"
        }
      ],
      "dockerImageVersionId": 30733,
      "isGpuEnabled": true,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 143.402814,
      "end_time": "2024-07-11T07:15:02.589551",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-07-11T07:12:39.186737",
      "version": "2.5.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}